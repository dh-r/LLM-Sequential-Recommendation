{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7425febd-1ce0-4c3d-92aa-716679968335",
   "metadata": {
    "papermill": {
     "duration": 0.003648,
     "end_time": "2023-06-26T12:07:48.596516",
     "exception": false,
     "start_time": "2023-06-26T12:07:48.592868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use a fine-tuned OpenAI model\n",
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bcca4a4-8913-4264-abac-66b07016d79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T13:35:57.885573Z",
     "start_time": "2023-02-12T13:35:55.990090Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-26T12:07:48.604624Z",
     "iopub.status.busy": "2023-06-26T12:07:48.604455Z"
    },
    "papermill": {
     "duration": 19.769609,
     "end_time": "2023-06-26T12:08:08.370053",
     "exception": false,
     "start_time": "2023-06-26T12:07:48.600444",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "from typing import Any\n",
    "import json\n",
    "import math\n",
    "\n",
    "from main.openai.openai_utils import openai_utils\n",
    "from create_prompt import create_prompt_completion_from_session\n",
    "import openai\n",
    "\n",
    "import random \n",
    "import time\n",
    "from collections import Counter\n",
    "import pickle \n",
    "import logging\n",
    "\n",
    "from main.data.session_dataset import *\n",
    "from main.abstract_model import Model\n",
    "\n",
    "from main.utils.top_k_computer import TopKComputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca8a5ad5-bfe4-480e-a90f-837d7a67d347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T13:35:57.889730Z",
     "start_time": "2023-02-12T13:35:57.888174Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-26T10:29:10.986959Z",
     "iopub.status.busy": "2023-06-26T10:29:10.986738Z",
     "iopub.status.idle": "2023-06-26T10:29:10.991452Z",
     "shell.execute_reply": "2023-06-26T10:29:10.989183Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = \"../../../beauty\"\n",
    "MODEL_NAME = \"<FILL IN MODEL NAME HERE>\" \n",
    "EMBEDDINGS_NAME = \"product_embeddings_openai\"\n",
    "TOP_K = 20\n",
    "TEMPERATURE = 0.5 \n",
    "TOP_P = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df92c2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:29:11.008682Z",
     "iopub.status.busy": "2023-06-26T10:29:11.008435Z",
     "iopub.status.idle": "2023-06-26T10:29:11.010360Z",
     "shell.execute_reply": "2023-06-26T10:29:11.010119Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_model_name = f\"{MODEL_NAME}_temp_{TEMPERATURE}_top_p_{TOP_P}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82bf42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: SessionDataset = SessionDataset.from_pickle(f\"{WORKING_DIR}/dataset.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77515583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:19:14.305859Z",
     "iopub.status.busy": "2023-06-26T10:19:14.305692Z",
     "iopub.status.idle": "2023-06-26T10:19:14.310241Z",
     "shell.execute_reply": "2023-06-26T10:19:14.309923Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4469"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset.get_test_prompts()\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b974ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:19:14.522065Z",
     "iopub.status.busy": "2023-06-26T10:19:14.521914Z",
     "iopub.status.idle": "2023-06-26T10:20:18.063067Z",
     "shell.execute_reply": "2023-06-26T10:20:18.062427Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>global_product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>ada_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1504</td>\n",
       "      <td>WAWO 15 Color Professionl Makeup Eyeshadow Cam...</td>\n",
       "      <td>[-0.008468648418784142, 0.014345130883157253, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>564</td>\n",
       "      <td>Xtreme Brite Brightening Gel 1oz.</td>\n",
       "      <td>[0.019681310281157494, 0.009377948939800262, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9963</td>\n",
       "      <td>Prada Candy By Prada Eau De Parfum Spray 1.7 O...</td>\n",
       "      <td>[-0.00300808809697628, -0.007103437092155218, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9839</td>\n",
       "      <td>Versace Bright Crystal Eau de Toilette Spray f...</td>\n",
       "      <td>[0.0053097945638000965, 0.0017624408937990665,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4132</td>\n",
       "      <td>Stella McCartney Stella</td>\n",
       "      <td>[-0.006986561696976423, -0.0015255995094776154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>438</td>\n",
       "      <td>Avalon Biotin B-Complex Thickening Conditioner...</td>\n",
       "      <td>[-0.011060410179197788, -0.017783403396606445,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9381</td>\n",
       "      <td>Better Living Classic Two Chamber Dispenser, W...</td>\n",
       "      <td>[-0.004991547204554081, 0.019236043095588684, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3618</td>\n",
       "      <td>Better Living The Ulti-Mate Dispenser</td>\n",
       "      <td>[-0.007757279556244612, 0.014554604887962341, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>11467</td>\n",
       "      <td>Crabtree  and  Evelyn - Gardener's Ultra-Moist...</td>\n",
       "      <td>[-0.010174826718866825, -0.0013344729086384177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6073</td>\n",
       "      <td>Crabtree  and  Evelyn 2792 Gardeners Hand Ther...</td>\n",
       "      <td>[0.0050934250466525555, -0.00951578002423048, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  global_product_id  \\\n",
       "0           0               1504   \n",
       "1           1                564   \n",
       "2           2               9963   \n",
       "3           3               9839   \n",
       "4           4               4132   \n",
       "5           5                438   \n",
       "6           6               9381   \n",
       "7           7               3618   \n",
       "8           8              11467   \n",
       "9           9               6073   \n",
       "\n",
       "                                                name  \\\n",
       "0  WAWO 15 Color Professionl Makeup Eyeshadow Cam...   \n",
       "1                  Xtreme Brite Brightening Gel 1oz.   \n",
       "2  Prada Candy By Prada Eau De Parfum Spray 1.7 O...   \n",
       "3  Versace Bright Crystal Eau de Toilette Spray f...   \n",
       "4                            Stella McCartney Stella   \n",
       "5  Avalon Biotin B-Complex Thickening Conditioner...   \n",
       "6  Better Living Classic Two Chamber Dispenser, W...   \n",
       "7              Better Living The Ulti-Mate Dispenser   \n",
       "8  Crabtree  and  Evelyn - Gardener's Ultra-Moist...   \n",
       "9  Crabtree  and  Evelyn 2792 Gardeners Hand Ther...   \n",
       "\n",
       "                                       ada_embedding  \n",
       "0  [-0.008468648418784142, 0.014345130883157253, ...  \n",
       "1  [0.019681310281157494, 0.009377948939800262, -...  \n",
       "2  [-0.00300808809697628, -0.007103437092155218, ...  \n",
       "3  [0.0053097945638000965, 0.0017624408937990665,...  \n",
       "4  [-0.006986561696976423, -0.0015255995094776154...  \n",
       "5  [-0.011060410179197788, -0.017783403396606445,...  \n",
       "6  [-0.004991547204554081, 0.019236043095588684, ...  \n",
       "7  [-0.007757279556244612, 0.014554604887962341, ...  \n",
       "8  [-0.010174826718866825, -0.0013344729086384177...  \n",
       "9  [0.0050934250466525555, -0.00951578002423048, ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_embeddings = pd.read_csv(f\"{WORKING_DIR}/{EMBEDDINGS_NAME}.csv.gzip\", compression=\"gzip\")\n",
    "product_embeddings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a7802e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:18.079760Z",
     "iopub.status.busy": "2023-06-26T10:20:18.079596Z",
     "iopub.status.idle": "2023-06-26T10:20:18.109052Z",
     "shell.execute_reply": "2023-06-26T10:20:18.108649Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1504,\n",
       "  'WAWO 15 Color Professionl Makeup Eyeshadow Camouflage Facial Concealer Neutral Palette'),\n",
       " (564, 'Xtreme Brite Brightening Gel 1oz.'),\n",
       " (9963, 'Prada Candy By Prada Eau De Parfum Spray 1.7 Oz For Women'),\n",
       " (9839, 'Versace Bright Crystal Eau de Toilette Spray for Women, 3 Ounce'),\n",
       " (4132, 'Stella McCartney Stella'),\n",
       " (438, 'Avalon Biotin B-Complex Thickening Conditioner, 14 Ounce'),\n",
       " (9381, 'Better Living Classic Two Chamber Dispenser, White'),\n",
       " (3618, 'Better Living The Ulti-Mate Dispenser'),\n",
       " (11467,\n",
       "  \"Crabtree  and  Evelyn - Gardener's Ultra-Moisturising Hand Therapy Pump - 250g/8.8 OZ\"),\n",
       " (6073, 'Crabtree  and  Evelyn 2792 Gardeners Hand Therapy (100ml, 3.4 oz)')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_id_to_name = product_embeddings[[\"global_product_id\", \"name\"]].set_index(\"global_product_id\").to_dict()[\"name\"]\n",
    "list(product_id_to_name.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4db34a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:18.117038Z",
     "iopub.status.busy": "2023-06-26T10:20:18.116862Z",
     "iopub.status.idle": "2023-06-26T10:20:18.138954Z",
     "shell.execute_reply": "2023-06-26T10:20:18.138608Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WAWO 15 Color Professionl Makeup Eyeshadow Camouflage Facial Concealer Neutral Palette',\n",
       "  1504),\n",
       " ('Xtreme Brite Brightening Gel 1oz.', 564),\n",
       " ('Prada Candy By Prada Eau De Parfum Spray 1.7 Oz For Women', 9963),\n",
       " ('Versace Bright Crystal Eau de Toilette Spray for Women, 3 Ounce', 9839),\n",
       " ('Stella McCartney Stella', 4132),\n",
       " ('Avalon Biotin B-Complex Thickening Conditioner, 14 Ounce', 438),\n",
       " ('Better Living Classic Two Chamber Dispenser, White', 9381),\n",
       " ('Better Living The Ulti-Mate Dispenser', 3618),\n",
       " (\"Crabtree  and  Evelyn - Gardener's Ultra-Moisturising Hand Therapy Pump - 250g/8.8 OZ\",\n",
       "  11467),\n",
       " ('Crabtree  and  Evelyn 2792 Gardeners Hand Therapy (100ml, 3.4 oz)', 6073)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name_to_id = product_embeddings[[\"global_product_id\", \"name\"]].set_index(\"name\").to_dict()[\"global_product_id\"]\n",
    "list(product_name_to_id.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "780bd3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:18.147622Z",
     "iopub.status.busy": "2023-06-26T10:20:18.147434Z",
     "iopub.status.idle": "2023-06-26T10:20:32.303343Z",
     "shell.execute_reply": "2023-06-26T10:20:32.302387Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_index_to_embedding = product_embeddings[[\"global_product_id\", \"ada_embedding\"]].set_index(\"global_product_id\").to_dict()[\"ada_embedding\"]\n",
    "product_index_to_embedding = {k: np.array(json.loads(v)) for k, v in product_index_to_embedding.items()}\n",
    "product_index_to_embedding = np.array(list(product_index_to_embedding.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b08e248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:32.319397Z",
     "iopub.status.busy": "2023-06-26T10:20:32.319150Z",
     "iopub.status.idle": "2023-06-26T10:20:32.323842Z",
     "shell.execute_reply": "2023-06-26T10:20:32.323522Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12101, 1536)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_index_to_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21cd17bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:32.331732Z",
     "iopub.status.busy": "2023-06-26T10:20:32.331586Z",
     "iopub.status.idle": "2023-06-26T10:20:32.334534Z",
     "shell.execute_reply": "2023-06-26T10:20:32.334234Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_index_to_id = list(product_id_to_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "895f50e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:58.916269Z",
     "iopub.status.busy": "2023-06-26T10:20:58.915933Z",
     "iopub.status.idle": "2023-06-26T10:20:58.939490Z",
     "shell.execute_reply": "2023-06-26T10:20:58.939109Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be computing for 4469 sessions\n",
      "Have to truncate with len(prompt): 8011 and len(session): 116\n",
      "Have to truncate with len(prompt): 5842 and len(session): 83\n",
      "Have to truncate with len(prompt): 5433 and len(session): 49\n",
      "Have to truncate with len(prompt): 5247 and len(session): 79\n",
      "Have to truncate with len(prompt): 5521 and len(session): 16\n",
      "Have to truncate with len(prompt): 7381 and len(session): 24\n",
      "Have to truncate with len(prompt): 5948 and len(session): 19\n",
      "Have to truncate with len(prompt): 7129 and len(session): 26\n",
      "Have to truncate with len(prompt): 8309 and len(session): 24\n",
      "Have to truncate with len(prompt): 5825 and len(session): 18\n",
      "Have to truncate with len(prompt): 5870 and len(session): 20\n",
      "Have to truncate with len(prompt): 6733 and len(session): 74\n",
      "Have to truncate with len(prompt): 14645 and len(session): 130\n",
      "Have to truncate with len(prompt): 6499 and len(session): 19\n",
      "Have to truncate with len(prompt): 12947 and len(session): 202\n",
      "Have to truncate with len(prompt): 10413 and len(session): 149\n",
      "Have to truncate with len(prompt): 8375 and len(session): 111\n",
      "Have to truncate with len(prompt): 10172 and len(session): 127\n",
      "Have to truncate with len(prompt): 6664 and len(session): 107\n",
      "Have to truncate with len(prompt): 6667 and len(session): 27\n",
      "Have to truncate with len(prompt): 5282 and len(session): 76\n",
      "Have to truncate with len(prompt): 5076 and len(session): 18\n",
      "Have to truncate with len(prompt): 6436 and len(session): 21\n",
      "Have to truncate with len(prompt): 7271 and len(session): 28\n",
      "Have to truncate with len(prompt): 7906 and len(session): 90\n",
      "Have to truncate with len(prompt): 5328 and len(session): 18\n",
      "Have to truncate with len(prompt): 7168 and len(session): 95\n",
      "Have to truncate with len(prompt): 6840 and len(session): 23\n",
      "Have to truncate with len(prompt): 5288 and len(session): 70\n",
      "Have to truncate with len(prompt): 5431 and len(session): 80\n",
      "Have to truncate with len(prompt): 6958 and len(session): 25\n",
      "Have to truncate with len(prompt): 5370 and len(session): 52\n",
      "Have to truncate with len(prompt): 5965 and len(session): 20\n",
      "Have to truncate with len(prompt): 7100 and len(session): 72\n",
      "Have to truncate with len(prompt): 8899 and len(session): 33\n",
      "Have to truncate with len(prompt): 7912 and len(session): 27\n",
      "Have to truncate with len(prompt): 6297 and len(session): 20\n",
      "Have to truncate with len(prompt): 5587 and len(session): 20\n",
      "Have to truncate with len(prompt): 5861 and len(session): 20\n",
      "Have to truncate with len(prompt): 6866 and len(session): 79\n",
      "Have to truncate with len(prompt): 5278 and len(session): 71\n",
      "Have to truncate with len(prompt): 8046 and len(session): 24\n",
      "Have to truncate with len(prompt): 9367 and len(session): 36\n",
      "Have to truncate with len(prompt): 5492 and len(session): 84\n",
      "Have to truncate with len(prompt): 5476 and len(session): 67\n",
      "Have to truncate with len(prompt): 7357 and len(session): 79\n",
      "Have to truncate with len(prompt): 6812 and len(session): 98\n",
      "Have to truncate with len(prompt): 16463 and len(session): 133\n",
      "Have to truncate with len(prompt): 5485 and len(session): 78\n",
      "Have to truncate with len(prompt): 5296 and len(session): 19\n",
      "Have to truncate with len(prompt): 5773 and len(session): 18\n",
      "Have to truncate with len(prompt): 8009 and len(session): 30\n",
      "Have to truncate with len(prompt): 8694 and len(session): 115\n",
      "Have to truncate with len(prompt): 6315 and len(session): 23\n",
      "Have to truncate with len(prompt): 8396 and len(session): 92\n",
      "Have to truncate with len(prompt): 7460 and len(session): 25\n",
      "Have to truncate with len(prompt): 5599 and len(session): 76\n",
      "Have to truncate with len(prompt): 5791 and len(session): 19\n",
      "Have to truncate with len(prompt): 6976 and len(session): 24\n",
      "Have to truncate with len(prompt): 6861 and len(session): 99\n",
      "Have to truncate with len(prompt): 7268 and len(session): 26\n",
      "Have to truncate with len(prompt): 11271 and len(session): 112\n",
      "Have to truncate with len(prompt): 5336 and len(session): 20\n",
      "Have to truncate with len(prompt): 10108 and len(session): 33\n",
      "Have to truncate with len(prompt): 5836 and len(session): 28\n",
      "Have to truncate with len(prompt): 5519 and len(session): 79\n",
      "Have to truncate with len(prompt): 6502 and len(session): 22\n",
      "Have to truncate with len(prompt): 7721 and len(session): 26\n",
      "Have to truncate with len(prompt): 10410 and len(session): 33\n",
      "Have to truncate with len(prompt): 11896 and len(session): 178\n",
      "Have to truncate with len(prompt): 5444 and len(session): 18\n",
      "Have to truncate with len(prompt): 5761 and len(session): 19\n",
      "Have to truncate with len(prompt): 5494 and len(session): 82\n",
      "Have to truncate with len(prompt): 7729 and len(session): 115\n",
      "Have to truncate with len(prompt): 9691 and len(session): 33\n",
      "Have to truncate with len(prompt): 8736 and len(session): 104\n",
      "Have to truncate with len(prompt): 6440 and len(session): 98\n",
      "Have to truncate with len(prompt): 7320 and len(session): 24\n",
      "Have to truncate with len(prompt): 5030 and len(session): 32\n",
      "Have to truncate with len(prompt): 5399 and len(session): 18\n",
      "Have to truncate with len(prompt): 6553 and len(session): 22\n",
      "Have to truncate with len(prompt): 5601 and len(session): 81\n",
      "Have to truncate with len(prompt): 6544 and len(session): 25\n",
      "Have to truncate with len(prompt): 11645 and len(session): 45\n",
      "Have to truncate with len(prompt): 5551 and len(session): 22\n",
      "Have to truncate with len(prompt): 7036 and len(session): 25\n",
      "Have to truncate with len(prompt): 5642 and len(session): 86\n",
      "Have to truncate with len(prompt): 6192 and len(session): 23\n",
      "Have to truncate with len(prompt): 5138 and len(session): 18\n",
      "Have to truncate with len(prompt): 6851 and len(session): 96\n",
      "Have to truncate with len(prompt): 5539 and len(session): 17\n",
      "Have to truncate with len(prompt): 5848 and len(session): 18\n",
      "Have to truncate with len(prompt): 5015 and len(session): 78\n",
      "Have to truncate with len(prompt): 5265 and len(session): 18\n",
      "Have to truncate with len(prompt): 5965 and len(session): 20\n",
      "Have to truncate with len(prompt): 5041 and len(session): 52\n",
      "Have to truncate with len(prompt): 6935 and len(session): 22\n",
      "Have to truncate with len(prompt): 6557 and len(session): 21\n",
      "Have to truncate with len(prompt): 6324 and len(session): 64\n",
      "Have to truncate with len(prompt): 8059 and len(session): 73\n",
      "Have to truncate with len(prompt): 8671 and len(session): 108\n",
      "Have to truncate with len(prompt): 7728 and len(session): 24\n",
      "Have to truncate with len(prompt): 7006 and len(session): 77\n",
      "Have to truncate with len(prompt): 7388 and len(session): 106\n",
      "Have to truncate with len(prompt): 9477 and len(session): 152\n",
      "Have to truncate with len(prompt): 15464 and len(session): 191\n",
      "Now at 4468\r"
     ]
    }
   ],
   "source": [
    "test_keys = list(test.keys())\n",
    "\n",
    "# Maps session_id to -> dict(item_name -> number of occurences in recommendation slate.)\n",
    "session_id_to_value_counts = {}\n",
    "\n",
    "print(f\"Will be computing for {len(test_keys)} sessions\")\n",
    "# Loop through sessions to get:\n",
    "#   1. The value counts of recommended items. \n",
    "#   2. The recommended item names that need to be re-embedded to get existing products\n",
    "#       from the catalog.\n",
    "session_id_to_prompts = {}\n",
    "for i, session_id in enumerate(test_keys): \n",
    "    test_session = test[session_id]\n",
    "    \n",
    "    test_session_used_in_prompt = test_session.copy()\n",
    "\n",
    "    if i % 1 == 0:    \n",
    "        print(f\"Now at {i}\", end=\"\\r\")\n",
    "    \n",
    "    # Create prompt.\n",
    "    prompt, _ = create_prompt_completion_from_session(test_session_used_in_prompt, product_id_to_name, 0)\n",
    "    \n",
    "    if len(prompt) > 5000: # Ada has a maximum token length of 2049, so around 6-9k chars.\n",
    "        # We need to truncate the prompt. \n",
    "        # For now we just take the last 20 items.\n",
    "        # It's too slow to process on a case-by-case basis.\n",
    "        print(f\"Have to truncate with len(prompt): {len(prompt)} and len(session): {len(test_session_used_in_prompt)}\")\n",
    "        test_session_used_in_prompt = test_session_used_in_prompt[-20:]\n",
    "        prompt, _ = create_prompt_completion_from_session(test_session_used_in_prompt, product_id_to_name, 0)\n",
    "    \n",
    "    session_id_to_prompts[session_id] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33b52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:58.952062Z",
     "iopub.status.busy": "2023-06-26T10:20:58.951819Z",
     "iopub.status.idle": "2023-06-26T10:20:59.042107Z",
     "shell.execute_reply": "2023-06-26T10:20:59.041745Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recs_filename = f\"{total_model_name}_recs.pickle\"\n",
    "\n",
    "try: \n",
    "    with open(recs_filename, \"rb\") as f: \n",
    "        session_id_to_value_counts = pickle.loads(f.read())\n",
    "except: \n",
    "\n",
    "    # Create batches of the prompts.\n",
    "    step_size = 20\n",
    "    cur_step = 0\n",
    "\n",
    "    session_id_and_prompts = list(session_id_to_prompts.items())\n",
    "\n",
    "    # Create embedding for each item. \n",
    "    # These embeddings are automatically saved in the cache, so that they \n",
    "    # can be used in the following code immediately.\n",
    "    while cur_step < len(session_id_to_prompts):\n",
    "        print(f\"Currently at {cur_step} of {len(session_id_to_prompts)}\")\n",
    "        \n",
    "        cur_session_id_and_prompts = session_id_and_prompts[cur_step:cur_step + step_size]\n",
    "\n",
    "        cur_prompts = [session_id_and_prompt[1] for session_id_and_prompt in cur_session_id_and_prompts]\n",
    "        cur_sessions = [session_id_and_prompt[0] for session_id_and_prompt in cur_session_id_and_prompts]\n",
    "\n",
    "        # Call the API to complete the prompts.\n",
    "        def call_openai(): \n",
    "            return openai.Completion.create(\n",
    "                model=MODEL_NAME,\n",
    "                prompt=cur_prompts,\n",
    "                max_tokens=50,\n",
    "                temperature=TEMPERATURE,\n",
    "                top_p=TOP_P,\n",
    "                n=TOP_K,\n",
    "                stop=\"###\"\n",
    "            )[\"choices\"]\n",
    "\n",
    "        try:\n",
    "            choices = call_openai()\n",
    "        except Exception as e: \n",
    "            print(f\"Failed call to openAI with exception {e}, trying again in 20 seconds..\")\n",
    "            time.sleep(40)\n",
    "\n",
    "            choices = call_openai()\n",
    "        \n",
    "        # Get the recommended item names.\n",
    "        predicted_item_names = [choice['text'].strip() for choice in choices]\n",
    "\n",
    "        # Reshape batched predicted item names.    \n",
    "        predicted_item_names = np.reshape(predicted_item_names, (-1, TOP_K))\n",
    "\n",
    "        for session_id, session_predicted_item_names in zip(cur_sessions, predicted_item_names):\n",
    "            # Get the value counts for each recommended item name, \n",
    "            # since the API might return duplicate items.\n",
    "            value_counts = dict(Counter(session_predicted_item_names))\n",
    "            \n",
    "            session_id_to_value_counts[session_id] = value_counts\n",
    "\n",
    "        cur_step += step_size\n",
    "\n",
    "    with open(recs_filename, \"wb\") as f: \n",
    "        pickle.dump(session_id_to_value_counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa0b4370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:20:59.052477Z",
     "iopub.status.busy": "2023-06-26T10:20:59.052301Z",
     "iopub.status.idle": "2023-06-26T10:25:09.399368Z",
     "shell.execute_reply": "2023-06-26T10:25:09.398365Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must compute 14852 new embeddings\n",
      "Currently at 1000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 2000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 3000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 4000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 5000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 6000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 7000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 8000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 9000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 10000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 11000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 12000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 13000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 14000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at 15000 of 14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/Documents/GitHub/LLM-sequential-recommendations/main/openai/openai_utils/openai_utils.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ada_embedding\"] = embeddings\n"
     ]
    }
   ],
   "source": [
    "to_embed = set()\n",
    "num_unknown_recommendations = 0\n",
    "num_known_recommendations = 0\n",
    "num_duplicate_recommendations = 0\n",
    "num_total_recommendations = 0\n",
    "for session_id, value_counts in session_id_to_value_counts.items():\n",
    "    for item_name in value_counts.keys(): \n",
    "        # If an item is not in the catalog, we need to embed it.\n",
    "        if not(openai_utils.in_cache(item_name)):\n",
    "            to_embed.add(item_name)\n",
    "        num_total_recommendations += value_counts[item_name]\n",
    "        if item_name not in product_name_to_id:\n",
    "            num_unknown_recommendations += value_counts[item_name]\n",
    "        else: \n",
    "            num_known_recommendations += value_counts[item_name]\n",
    "\n",
    "        if value_counts[item_name] > 1: \n",
    "            num_duplicate_recommendations += value_counts[item_name]\n",
    "\n",
    "\n",
    "to_embed = list(to_embed)\n",
    "print(f\"Must compute {len(to_embed)} new embeddings\")   \n",
    "to_embed = pd.DataFrame(to_embed, columns=[\"name\"])\n",
    "to_embed = to_embed[to_embed[\"name\"] != \"\"]\n",
    "\n",
    "# Create batches of the items that we need to embed.\n",
    "step_size = 1000\n",
    "batch_product_lookup = to_embed.iloc[0:step_size]\n",
    "cur_step = step_size\n",
    "processed_batches = []\n",
    "num_batches_processed = 0\n",
    "\n",
    "# Create embedding for each item. \n",
    "# These embeddings are automatically saved in the cache, so that they \n",
    "# can be used in the following code immediately.\n",
    "while not(batch_product_lookup.empty):\n",
    "    print(f\"Currently at {cur_step} of {len(to_embed)}\")\n",
    "    openai_utils.set_embeddings_from_df(batch_product_lookup)\n",
    "    processed_batches.append(batch_product_lookup)\n",
    "\n",
    "    batch_product_lookup = to_embed.iloc[cur_step:cur_step + step_size]\n",
    "    cur_step += step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5382d716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:25:09.419829Z",
     "iopub.status.busy": "2023-06-26T10:25:09.419609Z",
     "iopub.status.idle": "2023-06-26T10:27:29.846204Z",
     "shell.execute_reply": "2023-06-26T10:27:29.844723Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sessions done: 4464\r"
     ]
    }
   ],
   "source": [
    "# Now that we have embeddings for everything we need, we can finalize the \n",
    "# recommendations.\n",
    "recommendations = {}\n",
    "bug_item_list = []\n",
    "num_sessions_done = 0\n",
    "for session_id, value_counts in session_id_to_value_counts.items():\n",
    "    session_item_names = [product_id_to_name[item] for item in test[session_id]]\n",
    "    session_recommendations = []\n",
    "\n",
    "    duplicate_replacements = []\n",
    "    for item_name, count in value_counts.items(): \n",
    "\n",
    "        # If an item occurs more than once, we need its embedding to find \n",
    "        # neighbouring items. \n",
    "        # If an item is not in the catalog, we get a similar item that is in the catalog.\n",
    "        if count > 1 or item_name not in product_name_to_id: \n",
    "\n",
    "            # Assert that the item is in the cache, otherwise we would \n",
    "            # retrieve these embeddings from openAI again, which is slow and expensive.\n",
    "            if not openai_utils.in_cache(item_name): \n",
    "                # This always happens when item_name is an empty string, so we just \n",
    "                # create a zero embedding.\n",
    "                item_embedding = np.zeros((1, 1024 + 512))\n",
    "            else: \n",
    "\n",
    "                # Get item similarity using embedding \n",
    "                item_embedding = openai_utils.embedding_from_string(item_name) \n",
    "                if isinstance(item_embedding, str): \n",
    "                    item_embedding = json.loads(item_embedding)\n",
    "\n",
    "                item_embedding = np.array([item_embedding], dtype=np.float64)\n",
    "            predictions = (product_index_to_embedding @ item_embedding.T).T\n",
    "\n",
    "            # Get neighbouring item(s), and extend the recommendations for this \n",
    "            # session with the neighbouring item(s).\n",
    "            top_k_item_ids_indices = TopKComputer.compute_top_k(predictions, top_k=count + TOP_K)[0]\n",
    "            top_k_item_ids = [product_index_to_id[item_index] for item_index in top_k_item_ids_indices]\n",
    "\n",
    "            # Get names of the items that are not allowed to be added. \n",
    "            already_recommended_names = [product_id_to_name[item] for item in session_recommendations + duplicate_replacements]\n",
    "            upcoming_recommendations = value_counts\n",
    "            disallowed_items = already_recommended_names + list(upcoming_recommendations.keys()) + session_item_names\n",
    "\n",
    "            # Filter out disallowed items.\n",
    "            top_k_item_ids = [item for item in top_k_item_ids if product_id_to_name[item] not in disallowed_items]\n",
    "            \n",
    "            # We add the item itself if it exists.\n",
    "            item_exists : bool = item_name in product_name_to_id\n",
    "            if item_exists: \n",
    "                item_id = product_name_to_id[item_name]\n",
    "                session_recommendations.append(item_id)\n",
    "\n",
    "            # Truncate. \n",
    "            # If an item appeared `count` times, it needs `count - int(item_exists)` replacements.\n",
    "            # If the item exists, we have added it already, so we only need count - 1 replacements. \n",
    "            # If the item does not exist, we need count replacements.\n",
    "            top_k_item_ids = top_k_item_ids[:count - int(item_exists)]    \n",
    "\n",
    "            duplicate_replacements.extend(top_k_item_ids)\n",
    "\n",
    "        else:\n",
    "            # Simply add the id to the list of recommendations\n",
    "            item_id = product_name_to_id[item_name]\n",
    "            session_recommendations.append(item_id)\n",
    "    \n",
    "    session_recommendations.extend(duplicate_replacements)\n",
    "\n",
    "    num_sessions_done += 1\n",
    "    import random \n",
    "    if random.randint(0, 100) == 50: \n",
    "        print(f\"Num sessions done: {num_sessions_done}\", end=\"\\r\")      \n",
    "        \n",
    "    # print(f\"Session: {[product_id_to_name[item] for item in test[session_id]]}\")\n",
    "    # print(f\"Converted {value_counts} to {[product_id_to_name[item] for item in session_recommendations]}\")\n",
    "\n",
    "    recommendations.update({session_id: session_recommendations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67c0ec32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:27:29.909765Z",
     "iopub.status.busy": "2023-06-26T10:27:29.908955Z",
     "iopub.status.idle": "2023-06-26T10:27:29.934139Z",
     "shell.execute_reply": "2023-06-26T10:27:29.931849Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_pickle: bytes = pickle.dumps(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf3a6462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T10:27:29.968084Z",
     "iopub.status.busy": "2023-06-26T10:27:29.965744Z",
     "iopub.status.idle": "2023-06-26T10:27:30.083144Z",
     "shell.execute_reply": "2023-06-26T10:27:30.081558Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = f\"recs_openai_{total_model_name}\"\n",
    "\n",
    "with open(f\"{total_model_name}_statistics.txt\", \"w\") as f: \n",
    "    f.write(f\"num_unknown = {num_unknown_recommendations} \\n num_known = {num_known_recommendations} \\n num_duplicate = {num_duplicate_recommendations} \\n num_total = {num_total_recommendations}\")\n",
    "\n",
    "with open(f\"{filename}.pickle\", \"wb\") as file: \n",
    "    file.write(predictions_pickle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.805059,
   "end_time": "2023-06-26T12:08:11.436886",
   "environment_variables": {},
   "exception": null,
   "input_path": "session_finetuned.ipynb",
   "output_path": "session_finetuned.ipynb",
   "parameters": {
    "MODEL_NAME": "ada:ft-delivery-hero:dhr-finetune-singapore-epoch-10-2023-06-23-00-04-53",
    "TEMPERATURE": 1,
    "TOP_P": 0.25,
    "WORKING_DIR": "FP_SG/qcommerce/12-04-2023_one_month/session"
   },
   "start_time": "2023-06-26T12:07:47.631827",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7b0333b79102557606cd627c98bd6186cef0eaf6f73cdc9a9902d58be894465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
