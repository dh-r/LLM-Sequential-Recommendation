{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6e5b1a",
   "metadata": {
    "papermill": {
     "duration": 0.00861,
     "end_time": "2023-04-15T18:56:46.284277",
     "exception": false,
     "start_time": "2023-04-15T18:56:46.275667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate prompts for the variant `LLMSeqPromptGenList` (Section 4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd0d07",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.156373,
     "end_time": "2023-04-15T18:56:49.476637",
     "exception": false,
     "start_time": "2023-04-15T18:56:46.320264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "from main.data.session_dataset import SessionDataset\n",
    "from main.llm_based.similarity_model.llm_seq_sim import LLMSeqSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8dcac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 18.223049,
     "end_time": "2023-04-15T18:57:08.456366",
     "exception": false,
     "start_time": "2023-04-15T18:56:50.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET: Literal[\"beauty\", \"steam\"] = \"beauty\"\n",
    "TEST_DATA_PICKLE_NAME = f\"{DATASET}_dataset.pickle\"\n",
    "ITEM_NAMES_DF = f\"{DATASET}_item_names.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e1d23-d060-448c-8da6-22d5e917be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: SessionDataset = SessionDataset.from_pickle(open(TEST_DATA_PICKLE_NAME, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3909a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"max_session_length_for_decay_precomputation\": 500,\n",
    "    \"filter_prompt_items\": True,\n",
    "    \"batch_size\": 500,\n",
    "    \"dim_reduction_config\": {\n",
    "        \"reduction_config\": {\n",
    "            \"config\": {},\n",
    "            \"reduction_technique\": \"pca\"\n",
    "        },\n",
    "    \"normalize\": True,\n",
    "    \"reduced_dim_size\": 512\n",
    "  },\n",
    "  \"is_verbose\": True,\n",
    "  \"cores\": 15,\n",
    "  \"similarity_measure\": \"cosine\",\n",
    "  \"embedding_combination_strategy\": \"mean\",\n",
    "  \"combination_decay\": \"harmonic\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c8003",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2818.836833,
     "end_time": "2023-04-15T19:44:07.311860",
     "exception": false,
     "start_time": "2023-04-15T18:57:08.475027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model: LLMSeqSim = LLMSeqSim(**config)\n",
    "\n",
    "model.train(dataset.get_train_data(), dataset.get_item_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75b2fc",
   "metadata": {
    "papermill": {
     "duration": 0.002302,
     "end_time": "2023-04-15T19:44:07.316978",
     "exception": false,
     "start_time": "2023-04-15T19:44:07.314676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Compute the Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fe684-4f56-4a20-a830-a3bfd4473661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_df = pd.read_csv(ITEM_NAMES_DF, usecols=[\"ItemId\", \"name\"])\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda819ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_df[item_df['name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67278e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unnamed_item_ids = item_df[beauty_product_df['name'].isna()]\\\n",
    "    ['ItemId'].unique()\n",
    "unnamed_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530d91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sessions = dataset.get_train_data().groupby('SessionId')\n",
    "\n",
    "train_prompts = {}\n",
    "train_ground_truths = {}\n",
    "\n",
    "# For each session in the train data\n",
    "for session_id, session_data in sessions:\n",
    "    items = session_data['ItemId'].to_numpy()\n",
    "    \n",
    "    # Remove sessions completely when they have an unnamed product\n",
    "    if np.any(np.isin(items, unnamed_item_ids)):\n",
    "        print(\"Skip!\")\n",
    "        continue\n",
    "        \n",
    "    # Split the train prompt into a 'prompt' and 'ground-truth'.\n",
    "    # In a session of 'n' items, the first 'n-1' items are the prompt and the 'n'th' item is the ground truth. \n",
    "    train_prompts[session_id] = items[:-1]\n",
    "    train_ground_truths[session_id] = items[-1:]\n",
    "\n",
    "len(train_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113147e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 64.643522,
     "end_time": "2023-04-15T19:45:11.962519",
     "exception": false,
     "start_time": "2023-04-15T19:44:07.318997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_K = 20\n",
    "\n",
    "recommendations: dict[int, np.ndarray] = model.predict(\n",
    "    train_prompts, top_k=TOP_K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3b70b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(f\"Training prompt {train_prompts[0]} with ground truth {train_ground_truths[0]}\")\n",
    "print(f\"Recommended items for train prompt {recommendations[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225d876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(recommendations), len(train_ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a97531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grounded_recommendations = {}\n",
    "gt_not_in_recs = 0\n",
    "\n",
    "# For each top-k recommendatons by the model\n",
    "for session_id, rec_items in recommendations.items():\n",
    "    \n",
    "    # Skip recommendations which are unnamed products.\n",
    "    if any(item in unnamed_product_ids for item in rec_items):\n",
    "        print(f\"Skip session {session_id}!\")\n",
    "        continue\n",
    "        \n",
    "    # Get the ground truth (this is the last item of the original train session)\n",
    "    ground_truth = train_ground_truths[session_id][0]\n",
    "    \n",
    "    # If this ground truth is not part of the recommendation items, we prepend it.\n",
    "    if ground_truth not in rec_items:\n",
    "        gt_not_in_recs += 1\n",
    "        grounded_rec_items = [ground_truth] + rec_items[:-1].tolist()\n",
    "    else: # Otherwise we make sure the ground truth is on top of the list.\n",
    "        cleaned_recs = np.delete(rec_items, np.where(rec_items == ground_truth))\n",
    "        grounded_rec_items = [ground_truth] + cleaned_recs.tolist()\n",
    "    grounded_recommendations[session_id] = grounded_rec_items\n",
    "    \n",
    "# NOTE THAT GROUND_RECOMMENDATIONS MIGHT HAVE LENGTHS LONGER THAN TOP-K \n",
    "\n",
    "print(f\"For {(gt_not_in_recs / len(recommendations.items())) * 100}% of sessions the ground truth was not part of the recommendations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc249e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify that the ground truth is 'on top'.\n",
    "grounded_recommendations[0], train_ground_truths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c123b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_id_to_name = item_df.set_index('ItemId')\\\n",
    "    ['name'].to_dict()\n",
    "product_id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132460b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "textified_train_prompts = {}\n",
    "\n",
    "for session, rec_items in train_prompts.items():\n",
    "    textified_train_prompts[session] = [\n",
    "        product_id_to_name[product_id] for product_id in rec_items\n",
    "    ]\n",
    "\n",
    "textified_train_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3536948",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "textified_recommendations = {}\n",
    "\n",
    "for session, rec_items in grounded_recommendations.items():\n",
    "    textified_recommendations[session] = [\n",
    "        product_id_to_name[product_id] for product_id in rec_items\n",
    "    ]\n",
    "\n",
    "textified_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ddef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a recommender system assistant.\n",
    "Provide 20 unique item recommendations complementary to the user's item list, ordered by the confidence level of each recommendation.\n",
    "Ensure all recommendations are from items included in the data you are fine-tuned with. List only the item names.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"The user's item list are in the following lines\n",
    "delimited by BEGIN and END. Each item is in a separate line:\n",
    "BEGIN\n",
    "{user_item_list}\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "ASSISTANT_PROMPT_TEMPLATE = \"\"\"The recommendations are in the following\n",
    "lines, in decreasing confidence order. The recommendations are delimited by\n",
    "BEGIN and END. Each recommendation is in a separate line:\n",
    "BEGIN\n",
    "{ranked_recommendations}\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "def stringify_ranked_list(list_of_items):\n",
    "    stringified_ranked_list = \"\"\n",
    "    for i, item in enumerate(list_of_items, 1):\n",
    "        stringified_ranked_list += f\"{i}. {item}\\n\"\n",
    "    return stringified_ranked_list\n",
    "\n",
    "\n",
    "def create_prompt(train_prompt, recommendations, ranked_recommendations):\n",
    "\n",
    "    prompt = {}\n",
    "    prompt['messages'] = []\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT\n",
    "    })\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": USER_PROMPT_TEMPLATE.format(\n",
    "            user_item_list='\\n'.join(train_prompt),\n",
    "            recommendations='\\n'.join(recommendations)\n",
    "        )\n",
    "    })\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": ASSISTANT_PROMPT_TEMPLATE.format(\n",
    "            ranked_recommendations=stringify_ranked_list(ranked_recommendations)\n",
    "        )\n",
    "    })\n",
    "\n",
    "    return prompt\n",
    "\n",
    "create_prompt(train_prompt=textified_train_prompts[0],\n",
    "              recommendations=textified_recommendations[0],\n",
    "              ranked_recommendations=textified_recommendations[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b517b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_session_length = 2\n",
    "num_tokens = 0\n",
    "num_validation_cases = int(0.2 * len(train_prompts))\n",
    "tokens_per_message = 3\n",
    "tokens_per_name = 1\n",
    "\n",
    "train_cases = []\n",
    "validation_cases = []\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Shuffle session ids to get a random validation set.\n",
    "random.seed(42)\n",
    "session_ids = list(train_prompts.keys())\n",
    "random.shuffle(session_ids)\n",
    "\n",
    "for i, session_id in enumerate(session_ids): \n",
    "    train_session = train_prompts[session_id]\n",
    "\n",
    "    # We skip sessions that are too short.\n",
    "    if len(train_session) < min_session_length:\n",
    "        continue\n",
    "    \n",
    "    # Create prompt\n",
    "    train_prompt = textified_train_prompts[session_id]\n",
    "    session_recommendations = textified_recommendations[session_id]\n",
    "    shuffled_session_recommendations = session_recommendations.copy()\n",
    "    random.shuffle(shuffled_session_recommendations)\n",
    "    print(session_id, train_prompt, session_recommendations)\n",
    "    prompt = create_prompt(\n",
    "        train_prompt=train_prompt,\n",
    "        recommendations=shuffled_session_recommendations,\n",
    "        ranked_recommendations=session_recommendations\n",
    "    )\n",
    "\n",
    "    # We skip sessions that are too long.\n",
    "    num_prompt_tokens = 0\n",
    "    for message in prompt['messages']:\n",
    "        num_prompt_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_prompt_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_prompt_tokens += tokens_per_name\n",
    "    num_prompt_tokens += 3  # every reply is primed \n",
    "                            # with <|start|>assistant<|message|>\n",
    "    \n",
    "    if num_prompt_tokens > 4096:\n",
    "        continue\n",
    "\n",
    "    # Add to validation or training set.\n",
    "    if i < num_validation_cases: \n",
    "        validation_cases.append(prompt)\n",
    "    else: \n",
    "        num_tokens += num_prompt_tokens\n",
    "        train_cases.append(prompt)\n",
    "\n",
    "# Convert training to JSONL.\n",
    "train_cases = [\n",
    "    json.dumps(train_case) \n",
    "    for train_case in train_cases\n",
    "]\n",
    "train_string = '\\n'.join(train_cases)\n",
    "\n",
    "# Convert validation to JSONL.\n",
    "validation_cases = [\n",
    "    json.dumps(validation_case) \n",
    "    for validation_case in validation_cases\n",
    "]\n",
    "validation_string = '\\n'.join(validation_cases)\n",
    "\n",
    "with open(\"train_cases_llmseqprompt_genlist.jsonl\", \"w\") as f:\n",
    "    f.write(train_string) \n",
    "\n",
    "with open(\"validation_cases_llmseqprompt_genlist.jsonl\", \"w\") as f:\n",
    "    f.write(validation_string) \n",
    "\n",
    "print(f'Training cases: {len(train_cases)}')\n",
    "print(f'Validation cases: {len(validation_cases)}')\n",
    "print(f\"Num tokens: {num_tokens}\")\n",
    "cost = num_tokens * (0.008 / 1000)\n",
    "print(f\"Costs to train GPT-3 turbo one epoch, roughly: ${cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccea645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2909.815931,
   "end_time": "2023-04-15T19:45:15.481286",
   "environment_variables": {},
   "exception": null,
   "input_path": "model_bert.ipynb",
   "output_path": "model_bert.ipynb",
   "parameters": {
    "CORES": 12,
    "HYPERSEARCH": false,
    "IS_VERBOSE": true,
    "TOP_K": 20,
    "WORKING_DIR": "FP_SG/qcommerce/12-04-2023_one_month/session"
   },
   "start_time": "2023-04-15T18:56:45.665355",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f788e71502201775ebe5fd014c14b82df146d1d4385a1e3ba9d4321db0a70aa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
