{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7119fd-4203-4a78-9595-ee29aebb6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "from typing import Literal\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a33a6e-1c7c-4533-8e2b-44c2eec9ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in name of finetuned_model.\n",
    "MODEL_NAME = \"\"\n",
    "\n",
    "DATASET: Literal[\"beauty\", \"steam\"] = \"beauty\"\n",
    "\n",
    "# Name of the pickle with the test data for Beauty.\n",
    "TEST_DATA_PICKLE_NAME = f\"test_data_{DATASET}.pickle\"\n",
    "\n",
    "# Name of the embeddings DF for \n",
    "EMBEDDINGS_NAME = f\"embeddings_{DATASET}.csv.gz\"\n",
    "\n",
    "# Pickles generated by the 'generate_finetune_prompts` notebook.\n",
    "CLUSTER_TO_POPULAR_ITEM_PICKLE = \"cluster_to_popular_item.pkl\"\n",
    "GLOBAL_PRODUCT_ID_TO_PRODUCT_PICKLE = \"global_product_id_to_cluster.pkl\"\n",
    "\n",
    "# Fill in OpenAI key\n",
    "OPENAI_KEY = \"\"\n",
    "\n",
    "# Hyperparameters\n",
    "TOP_K = 20\n",
    "TEMPERATURE = 0\n",
    "TOP_P = 1.0\n",
    "\n",
    "# Correspond to respectively 4.1 to 4.4\n",
    "VARIANT: Literal[\"genitem\", \"genlist\", \"classify\", \"rank\"] = \"classify\"\n",
    "\n",
    "TOTAL_MODEL_NAME = f\"{MODEL_NAME}_{VARIANT}_temp_{TEMPERATURE}_top_p_{TOP_P}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63dd13-b8d4-4f93-a6d5-b38f5d6d436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_completion_classify(completion: str) -> list[str]:\n",
    "    recommendations = []\n",
    "    items = re.findall(r\"\\d+\\.\\s(.*?)\\n\", completion)\n",
    "    for i, item in enumerate(items, start=1):\n",
    "        recommendations.append(item)\n",
    "    return recommendations[:TOP_K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc903f4e-c479-4e6f-bdda-f118f0e9d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"You are a recommender system assistant. You have access to the user's previous purchases and a list of availabe products.\n",
    "Provide 20 product recommendations for this user, only select from the available products.\n",
    "\"\"\",\n",
    "}\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "The user's previous purchases: \n",
    "{user_item_list}\n",
    "\n",
    "Available products:\n",
    "{potential_recommendation_categories}\n",
    "\n",
    "\n",
    "Please remember to only select recommendations from the available products.\n",
    "\"\"\",\n",
    "}\n",
    "parse_method = parse_completion_classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b2d9b-7889-43ec-ac27-735abb77d5eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load test prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8987e-510c-43d1-88b5-533ff5af9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts, _ = pickle.load(open(f\"{TEST_DATA_PICKLE_NAME}\", \"rb\"))\n",
    "test_prompts[list(test_prompts.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8ae1b-8535-46ea-8c06-b6fb3b6e036f",
   "metadata": {},
   "source": [
    "## Get embeddings and build lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a871c18-c647-4790-936d-531875faf74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings = pd.read_csv(\n",
    "    f\"{EMBEDDINGS_NAME}\", compression=\"gzip\"\n",
    ")\n",
    "product_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76049a-8ee9-4cb2-99bc-270530ffdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_to_name = (\n",
    "    product_embeddings[[\"ItemId\", \"name\"]]\n",
    "    .set_index(\"ItemId\")\n",
    "    .to_dict()[\"name\"]\n",
    ")\n",
    "product_name_to_id = (\n",
    "    product_embeddings[[\"ItemId\", \"name\"]]\n",
    "    .set_index(\"name\")\n",
    "    .to_dict()[\"ItemId\"]\n",
    ")\n",
    "product_index_to_embedding = (\n",
    "    product_embeddings[[\"ItemId\", \"embedding\"]]\n",
    "    .set_index(\"ItemId\")\n",
    "    .to_dict()[\"embedding\"]\n",
    ")\n",
    "product_index_to_embedding = {\n",
    "    k: np.array(json.loads(v)) for k, v in product_index_to_embedding.items()\n",
    "}\n",
    "product_index_to_embedding = np.array(list(product_index_to_embedding.values()))\n",
    "product_index_to_id = list(product_id_to_name.keys())\n",
    "product_id_to_index = {idx: i for i, idx in enumerate(product_index_to_id)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5b094-4f42-4ae3-b93f-6cc659edc563",
   "metadata": {},
   "source": [
    "## Load cluster information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5183a63-856f-4699-995e-053f38f682a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLUSTER_TO_POPULAR_ITEM_PICKLE, \"rb\") as infile:\n",
    "    cluster_to_popular_item = pickle.load(infile)\n",
    "cluster_to_popular_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e9c18-e791-47c6-8bbf-306bed83af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GLOBAL_PRODUCT_ID_TO_CLUSTER_PICKLE, \"rb\") as infile:\n",
    "    global_product_id_to_cluster = pickle.load(infile)\n",
    "global_product_id_to_cluster[575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed4abc-3aea-4650-9569-98587a097bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = [product_id_to_name[item] for item in cluster_to_popular_item.values()]\n",
    "all_categories[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f021f-faeb-4e50-9014-09231b1dbb39",
   "metadata": {},
   "source": [
    "## Compute test prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3463b9-5a63-4369-8bd5-164cacaee68e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_messages: list[tuple[int, list[str]]] = []\n",
    "\n",
    "for session_id, prompt in test_prompts.items():\n",
    "    custom_user_message = user_message.copy()\n",
    "    custom_user_message[\"content\"] = custom_user_message[\"content\"].replace(\"{user_item_list}\", \"\\n\".join([product_id_to_name[i] for i in prompt]))\n",
    "    custom_user_message[\"content\"] = custom_user_message[\"content\"].replace(\"{potential_recommendation_categories}\", \"\\n\".join(all_categories))\n",
    "    test_messages.append((session_id, [system_message, custom_user_message]))\n",
    "test_messages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a436ef-39e8-4c0c-abaa-005449af9bcd",
   "metadata": {},
   "source": [
    "# Compute completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f3687-ca80-43fa-a9da-1cfefb1a227c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "completions: list[tuple[int, str]] = []\n",
    "\n",
    "# Use async API to get parallel requests.\n",
    "# Make sure batch_size is not too high otherwise we might hit rate limits.\n",
    "async def run_completions():\n",
    "    client = AsyncOpenAI(\n",
    "        api_key=OPENAI_KEY,\n",
    "    )\n",
    "\n",
    "    batch_size = 150\n",
    "    for i in tqdm(range(0, len(test_messages), batch_size)):\n",
    "        start_batch = i\n",
    "        end_batch = i + batch_size\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        print(f\"Completion batch {start_batch} - {end_batch}\")\n",
    "\n",
    "        requests = []\n",
    "        for _, messages in test_messages[start_batch:end_batch]:\n",
    "            requests.append(\n",
    "                client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    temperature=TEMPERATURE,\n",
    "                    top_p=TOP_P,\n",
    "                    messages=messages,\n",
    "                )\n",
    "            )\n",
    "        responses = await asyncio.gather(*requests)\n",
    "        for (session_id, _), response in zip(test_messages[start_batch:end_batch], responses):\n",
    "            completions.append((session_id, response.choices[0].message.content))\n",
    "            \n",
    "        print(f\"Finished batch {start_batch} - {end_batch}. Took {time.perf_counter() - start_time} seconds.\")\n",
    "\n",
    "\n",
    "await run_completions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fac383-2a4c-4942-a738-551634387083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(completions, open(f\"completions_openai_{total_model_name}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900c7d7-6ad4-46e0-8ce0-6b06f10812c2",
   "metadata": {},
   "source": [
    "### Parse completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ece951-85dc-4518-bb25-ea6625977dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_completions: list[tuple[int, list[str]]] = []\n",
    "for session_id, response in tqdm(completions):\n",
    "    parsed_response: list[str] = parse_method(response)\n",
    "    if parsed_response is None:\n",
    "        break\n",
    "    parsed_completions.append((session_id, parsed_response))\n",
    "parsed_completions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f63ee-4fa6-43f6-8c04-96fc88938b2f",
   "metadata": {},
   "source": [
    "# Completed product names to global product ids\n",
    "First we try to map to the exact product name and otherwise we use embeddings to find the closest item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195e786-8591-4114-9ca8-5f730adee16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff88b-38f5-4ab2-95c3-aa7aeeb3d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "recommendations: dict[int, list[int]] = {}\n",
    "unmappable_items: set = set()\n",
    "duplicate_count = 0\n",
    "exact_match = 0\n",
    "not_exact_match = 0\n",
    "for session_id, items in tqdm(parsed_completions):\n",
    "    recommendations[session_id] = []\n",
    "\n",
    "    items_so_far = set()\n",
    "\n",
    "    # Map to item from rerank list\n",
    "    for item in items:\n",
    "        if item in all_categories:\n",
    "            exact_match += 1\n",
    "            match_from_categories = item\n",
    "        else:\n",
    "            not_exact_match += 1\n",
    "            match_from_categories, match_score = process.extractOne(item, all_categories)\n",
    "            \n",
    "        if match_from_categories in items_so_far:\n",
    "            # Fall back on the next closest\n",
    "            for match, match_score in process.extract(item, all_categories, limit=len(all_categories)):\n",
    "                if match not in items_so_far:\n",
    "                    match_from_categories = match\n",
    "            duplicate_count += 1\n",
    "        \n",
    "        recommendations[session_id].append(product_name_to_id[match_from_categories])\n",
    "        items_so_far.add(match_from_categories)\n",
    "\n",
    "    if len(items_so_far.intersection(set(all_categories))) != len(items_so_far):\n",
    "        print(\"Panic\")\n",
    "\n",
    "print(duplicate_count)\n",
    "print(exact_match)\n",
    "print(not_exact_match)\n",
    "\n",
    "len(recommendations), recommendations[list(recommendations.keys())[0]]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1ff26-d74d-4a8b-b7d9-535110b24676",
   "metadata": {},
   "source": [
    "Find closest actual item (with global product id) . Try to prevent duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16e8ad-33b4-4e08-945d-beb5df013163",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbf5d8-77a4-4c08-8774-5fbfa4ea0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(recommendations, open(f\"recs_openai_{total_model_name}\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
