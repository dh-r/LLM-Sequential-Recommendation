{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6e5b1a",
   "metadata": {
    "papermill": {
     "duration": 0.00861,
     "end_time": "2023-04-15T18:56:46.284277",
     "exception": false,
     "start_time": "2023-04-15T18:56:46.275667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate prompts for the variant `LLMSeqPromptGenItem` (Section 4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd0d07",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.156373,
     "end_time": "2023-04-15T18:56:49.476637",
     "exception": false,
     "start_time": "2023-04-15T18:56:46.320264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "from main.data.session_dataset import SessionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8dcac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 18.223049,
     "end_time": "2023-04-15T18:57:08.456366",
     "exception": false,
     "start_time": "2023-04-15T18:56:50.233317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET: Literal[\"beauty\", \"steam\"] = \"beauty\"\n",
    "TEST_DATA_PICKLE_NAME = f\"{DATASET}_dataset.pickle\"\n",
    "ITEM_NAMES_DF = f\"{DATASET}_item_names.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e1d23-d060-448c-8da6-22d5e917be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: SessionDataset = SessionDataset.from_pickle(open(TEST_DATA_PICKLE_NAME, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fe684-4f56-4a20-a830-a3bfd4473661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_df = pd.read_csv(ITEM_NAMES_DF, usecols=[\"ItemId\", \"name\"])\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda819ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_df[item_df['name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67278e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unnamed_item_ids = item_df[beauty_product_df['name'].isna()]\\\n",
    "    ['ItemId'].unique()\n",
    "unnamed_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530d91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sessions = dataset.get_train_data().groupby('SessionId')\n",
    "\n",
    "train_prompts = {}\n",
    "train_ground_truths = {}\n",
    "\n",
    "# For each session in the train data\n",
    "for session_id, session_data in sessions:\n",
    "    items = session_data['ItemId'].to_numpy()\n",
    "    \n",
    "    # Remove sessions completely when they have an unnamed product\n",
    "    if np.any(np.isin(items, unnamed_item_ids)):\n",
    "        print(\"Skip!\")\n",
    "        continue\n",
    "        \n",
    "    # Split the train prompt into a 'prompt' and 'ground-truth'.\n",
    "    # In a session of 'n' items, the first 'n-1' items are the prompt and the 'n'th' item is the ground truth. \n",
    "    train_prompts[session_id] = items[:-1]\n",
    "    train_ground_truths[session_id] = items[-1:]\n",
    "\n",
    "len(train_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c123b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_id_to_name = item_df.set_index('ItemId')\\\n",
    "    ['name'].to_dict()\n",
    "product_id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132460b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "textified_train_prompts = {}\n",
    "\n",
    "for session, rec_items in train_prompts.items():\n",
    "    textified_train_prompts[session] = [\n",
    "        product_id_to_name[product_id] for product_id in rec_items\n",
    "    ]\n",
    "\n",
    "textified_train_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ddef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Provide a unique item recommendation that is complementary to the user's item list. \n",
    "Ensure the recommendation is from items included in the data you are fine-tuned with. List only the item name.\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"The user's item list:\\n{user_item_list}\"\"\"\n",
    "\n",
    "ASSISTANT_PROMPT_TEMPLATE = \"\"\"{ground_truth}\"\"\"\n",
    "\n",
    "def create_prompt(train_prompt, ground_truth):\n",
    "\n",
    "    prompt = {}\n",
    "    prompt['messages'] = []\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT\n",
    "    })\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": USER_PROMPT_TEMPLATE.format(\n",
    "            user_item_list='\\n'.join(train_prompt)\n",
    "        )\n",
    "    })\n",
    "    prompt['messages'].append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": ASSISTANT_PROMPT_TEMPLATE.format(\n",
    "            ground_truth=ground_truth\n",
    "        )\n",
    "    })\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b517b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_session_length = 2\n",
    "num_tokens = 0\n",
    "num_validation_cases = int(0.2 * len(train_prompts))\n",
    "tokens_per_message = 3\n",
    "tokens_per_name = 1\n",
    "\n",
    "train_cases = []\n",
    "validation_cases = []\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Shuffle session ids to get a random validation set.\n",
    "random.seed(42)\n",
    "session_ids = list(train_prompts.keys())\n",
    "random.shuffle(session_ids)\n",
    "\n",
    "for i, session_id in enumerate(session_ids): \n",
    "    train_session = train_prompts[session_id]\n",
    "\n",
    "    # We skip sessions that are too short.\n",
    "    if len(train_session) < min_session_length:\n",
    "        continue\n",
    "    \n",
    "    # Create prompt\n",
    "    train_prompt = textified_train_prompts[session_id]\n",
    "    prompt = create_prompt(\n",
    "        train_prompt=train_prompt,\n",
    "        ground_truth=train_ground_truths[session_id]\n",
    "    )\n",
    "\n",
    "    # We skip sessions that are too long.\n",
    "    num_prompt_tokens = 0\n",
    "    for message in prompt['messages']:\n",
    "        num_prompt_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_prompt_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_prompt_tokens += tokens_per_name\n",
    "    num_prompt_tokens += 3  # every reply is primed \n",
    "                            # with <|start|>assistant<|message|>\n",
    "    \n",
    "    if num_prompt_tokens > 4096:\n",
    "        continue\n",
    "\n",
    "    # Add to validation or training set.\n",
    "    if i < num_validation_cases: \n",
    "        validation_cases.append(prompt)\n",
    "    else: \n",
    "        num_tokens += num_prompt_tokens\n",
    "        train_cases.append(prompt)\n",
    "\n",
    "# Convert training to JSONL.\n",
    "train_cases = [\n",
    "    json.dumps(train_case) \n",
    "    for train_case in train_cases\n",
    "]\n",
    "train_string = '\\n'.join(train_cases)\n",
    "\n",
    "# Convert validation to JSONL.\n",
    "validation_cases = [\n",
    "    json.dumps(validation_case) \n",
    "    for validation_case in validation_cases\n",
    "]\n",
    "validation_string = '\\n'.join(validation_cases)\n",
    "\n",
    "with open(\"train_cases_llmseqprompt_genitem.jsonl\", \"w\") as f:\n",
    "    f.write(train_string) \n",
    "\n",
    "with open(\"validation_cases_llmseqprompt_genitem.jsonl\", \"w\") as f:\n",
    "    f.write(validation_string) \n",
    "\n",
    "print(f'Training cases: {len(train_cases)}')\n",
    "print(f'Validation cases: {len(validation_cases)}')\n",
    "print(f\"Num tokens: {num_tokens}\")\n",
    "cost = num_tokens * (0.008 / 1000)\n",
    "print(f\"Costs to train GPT-3 turbo one epoch, roughly: ${cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2909.815931,
   "end_time": "2023-04-15T19:45:15.481286",
   "environment_variables": {},
   "exception": null,
   "input_path": "model_bert.ipynb",
   "output_path": "model_bert.ipynb",
   "parameters": {
    "CORES": 12,
    "HYPERSEARCH": false,
    "IS_VERBOSE": true,
    "TOP_K": 20,
    "WORKING_DIR": "FP_SG/qcommerce/12-04-2023_one_month/session"
   },
   "start_time": "2023-04-15T18:56:45.665355",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f788e71502201775ebe5fd014c14b82df146d1d4385a1e3ba9d4321db0a70aa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
