{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7119fd-4203-4a78-9595-ee29aebb6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "from typing import Literal\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a33a6e-1c7c-4533-8e2b-44c2eec9ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in name of finetuned_model.\n",
    "MODEL_NAME = \"\"\n",
    "\n",
    "DATASET: Literal[\"beauty\", \"steam\"] = \"beauty\"\n",
    "\n",
    "# Name of the pickle with the test data for Beauty.\n",
    "TEST_DATA_PICKLE_NAME = f\"test_data_{DATASET}.pickle\"\n",
    "\n",
    "# Name of the embeddings DF for \n",
    "EMBEDDINGS_NAME = f\"embeddings_{DATASET}.csv.gz\"\n",
    "\n",
    "# Points to the pickle with the recommendation to rerank\n",
    "OTHER_MODEL_RECOMMENDATIONS = f\"llmseqsim_{DATASET}_recommendations.pkl\"\n",
    "\n",
    "# Fill in OpenAI key\n",
    "OPENAI_KEY = \"\"\n",
    "\n",
    "# Hyperparameters\n",
    "TOP_K = 20\n",
    "TEMPERATURE = 0\n",
    "TOP_P = 1.0\n",
    "\n",
    "# Correspond to respectively 4.1 to 4.4\n",
    "VARIANT: Literal[\"genitem\", \"genlist\", \"classify\", \"rank\"] = \"rank\"\n",
    "\n",
    "TOTAL_MODEL_NAME = f\"{MODEL_NAME}_{VARIANT}_temp_{TEMPERATURE}_top_p_{TOP_P}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63dd13-b8d4-4f93-a6d5-b38f5d6d436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_completion_rank(completion: str) -> list[str]:\n",
    "    recommendations = []\n",
    "    items = re.findall(r\"\\d+\\.\\s(.*?)\\n\", completion)\n",
    "    for i, item in enumerate(items, start=1):\n",
    "        recommendations.append(item)\n",
    "    return recommendations[:TOP_K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc903f4e-c479-4e6f-bdda-f118f0e9d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a recommender system assistant.\\nYou have access to the user's previous purchases and a list of availabe products.\\n Provide 20 product recommendations for this user, only select from the available products.\\n\",\n",
    "}\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "The user's previous purchases: \n",
    "{user_item_list}\n",
    "\n",
    "Available products:\n",
    "{recommendations_to_rerank}\n",
    "\n",
    "\n",
    "Please remember to only select recommendations from the available products.\n",
    "\"\"\",\n",
    "}\n",
    "parse_method = parse_completion_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b2d9b-7889-43ec-ac27-735abb77d5eb",
   "metadata": {},
   "source": [
    "## Load test prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8987e-510c-43d1-88b5-533ff5af9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts, _ = pickle.load(open(f\"{TEST_DATA_PICKLE_NAME}\", \"rb\"))\n",
    "test_prompts[list(test_prompts.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66865d3f-3f36-469d-8b62-a477c9fb83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recommendations_from_seqsim = pickle.load(open(OTHER_MODEL_RECOMMENDATIONS, \"rb\"))\n",
    "test_recommendations_from_seqsim[list(test_prompts.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8ae1b-8535-46ea-8c06-b6fb3b6e036f",
   "metadata": {},
   "source": [
    "## Get embeddings and build lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a871c18-c647-4790-936d-531875faf74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings = pd.read_csv(\n",
    "    f\"{EMBEDDINGS_NAME}\", compression=\"gzip\"\n",
    ")\n",
    "product_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a23dd7-5a89-4066-ac08-7a0d1d13a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_to_name = (\n",
    "    product_embeddings[[\"ItemId\", \"name\"]]\n",
    "    .set_index(\"ItemId\")\n",
    "    .to_dict()[\"name\"]\n",
    ")\n",
    "product_name_to_id = (\n",
    "    product_embeddings[[\"ItemId\", \"name\"]]\n",
    "    .set_index(\"name\")\n",
    "    .to_dict()[\"ItemId\"]\n",
    ")\n",
    "product_index_to_embedding = (\n",
    "    product_embeddings[[\"ItemId\", \"embedding\"]]\n",
    "    .set_index(\"ItemId\")\n",
    "    .to_dict()[\"embedding\"]\n",
    ")\n",
    "product_index_to_embedding = {\n",
    "    k: np.array(json.loads(v)) for k, v in product_index_to_embedding.items()\n",
    "}\n",
    "product_index_to_embedding = np.array(list(product_index_to_embedding.values()))\n",
    "product_index_to_id = list(product_id_to_name.keys())\n",
    "product_id_to_index = {idx: i for i, idx in enumerate(product_index_to_id)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f200116-6429-443d-9f45-61f456c29460",
   "metadata": {},
   "source": [
    "## Compute test prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c624e-85e9-42ca-8db9-e95336ac39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages: list[tuple[int, list[str]]] = []\n",
    "\n",
    "for session_id, prompt in test_prompts.items():\n",
    "    custom_user_message = user_message.copy()\n",
    "    custom_user_message[\"content\"] = custom_user_message[\"content\"].replace(\"{user_item_list}\", \"\\n\".join([product_id_to_name[i] for i in prompt]))\n",
    "    \n",
    "    seq_sim_recs = [product_id_to_name[i] for i in test_recommendations_from_seqsim[session_id]]\n",
    "    random.shuffle(seq_sim_recs)\n",
    "    custom_user_message[\"content\"] = custom_user_message[\"content\"].replace(\"{recommendations_to_rerank}\", \"\\n\".join(seq_sim_recs))\n",
    "    test_messages.append((session_id, [system_message, custom_user_message]))\n",
    "test_messages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a436ef-39e8-4c0c-abaa-005449af9bcd",
   "metadata": {},
   "source": [
    "# Compute completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f3687-ca80-43fa-a9da-1cfefb1a227c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "completions: list[tuple[int, str]] = []\n",
    "\n",
    "# Use async API to get parallel requests.\n",
    "# Make sure batch_size is not too high otherwise we might hit rate limits.\n",
    "async def run_completions():\n",
    "    client = AsyncOpenAI(\n",
    "        api_key=OPENAI_KEY,\n",
    "    )\n",
    "\n",
    "    batch_size = 150\n",
    "    for i in tqdm(range(0, len(test_messages), batch_size)):\n",
    "        start_batch = i\n",
    "        end_batch = i + batch_size\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        print(f\"Completion batch {start_batch} - {end_batch}\")\n",
    "\n",
    "        requests = []\n",
    "        for _, messages in test_messages[start_batch:end_batch]:\n",
    "            requests.append(\n",
    "                client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    temperature=TEMPERATURE,\n",
    "                    top_p=TOP_P,\n",
    "                    messages=messages,\n",
    "                )\n",
    "            )\n",
    "        responses = await asyncio.gather(*requests)\n",
    "        for (session_id, _), response in zip(test_messages[start_batch:end_batch], responses):\n",
    "            completions.append((session_id, response.choices[0].message.content))\n",
    "            \n",
    "        print(f\"Finished batch {start_batch} - {end_batch}. Took {time.perf_counter() - start_time} seconds.\")\n",
    "\n",
    "\n",
    "await run_completions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fac383-2a4c-4942-a738-551634387083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(completions, open(f\"completions_openai_{total_model_name}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900c7d7-6ad4-46e0-8ce0-6b06f10812c2",
   "metadata": {},
   "source": [
    "### Parse completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ece951-85dc-4518-bb25-ea6625977dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_completions: list[tuple[int, list[str]]] = []\n",
    "for session_id, response in tqdm(completions):\n",
    "    parsed_response: list[str] = parse_method(response)\n",
    "    if len(parsed_response) > TOP_K:\n",
    "    if parsed_response is None:\n",
    "        break\n",
    "    parsed_completions.append((session_id, parsed_response))\n",
    "parsed_completions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f63ee-4fa6-43f6-8c04-96fc88938b2f",
   "metadata": {},
   "source": [
    "# Completed product names to global product ids\n",
    "First we try to map to the exact product name and otherwise we use embeddings to find the closest item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff88b-38f5-4ab2-95c3-aa7aeeb3d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "recommendations: dict[int, list[int]] = {}\n",
    "unmappable_items: set = set()\n",
    "duplicate_count = 0\n",
    "exact_match = 0\n",
    "not_exact_match = 0\n",
    "for session_id, items in tqdm(parsed_completions):\n",
    "    recommendations[session_id] = []\n",
    "\n",
    "    seq_sim_recs = [product_id_to_name[i] for i in test_recommendations_from_seqsim[session_id]]\n",
    "    seq_sim_recs_set = set(seq_sim_recs)\n",
    "\n",
    "    items_so_far = set()\n",
    "\n",
    "    # Map to item from rerank list\n",
    "    for item in items:\n",
    "        if item in seq_sim_recs_set:\n",
    "            exact_match += 1\n",
    "            match_from_seq_sim = item\n",
    "        else:\n",
    "            not_exact_match += 1\n",
    "            match_from_seq_sim, match_score = process.extractOne(item, seq_sim_recs)\n",
    "            \n",
    "        if match_from_seq_sim in items_so_far:\n",
    "            # Fall back on the next closest\n",
    "            for match, match_score in process.extract(item, seq_sim_recs, limit=len(seq_sim_recs)):\n",
    "                if match not in items_so_far:\n",
    "                    match_from_seq_sim = match\n",
    "            duplicate_count += 1\n",
    "        \n",
    "        recommendations[session_id].append(product_name_to_id[match_from_seq_sim])\n",
    "        items_so_far.add(match_from_seq_sim)\n",
    "\n",
    "    if len(items_so_far.intersection(seq_sim_recs_set)) != len(items_so_far):\n",
    "        print(\"Panic\")\n",
    "\n",
    "print(duplicate_count)\n",
    "print(exact_match)\n",
    "print(not_exact_match)\n",
    "\n",
    "len(recommendations), recommendations[list(recommendations.keys())[0]]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1ff26-d74d-4a8b-b7d9-535110b24676",
   "metadata": {},
   "source": [
    "Find closest actual item (with global product id) . Try to prevent duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16e8ad-33b4-4e08-945d-beb5df013163",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbf5d8-77a4-4c08-8774-5fbfa4ea0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(recommendations, open(f\"recs_openai_{total_model_name}\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
